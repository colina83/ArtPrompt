{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19290f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import json  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2deea0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d06ca",
   "metadata": {},
   "source": [
    "# Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4126a",
   "metadata": {},
   "source": [
    "### 1.- Defining Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e0384",
   "metadata": {},
   "source": [
    "The cell below contains code that searches for an artist using different resources of the Harvard Art Museum API - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1fd8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "key  = os.environ['HARVARD_API_KEY']\n",
    "artist = \"Cezanne\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219f5d1",
   "metadata": {},
   "source": [
    "The cell below will use the title to find an object with the artist name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4c4004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(f'https://api.harvardartmuseums.org/object?person={artist}&apikey={key}')\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d9a6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the info and records\n",
    "info = data['info']\n",
    "records = data['records']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45906c81",
   "metadata": {},
   "source": [
    "## Results with Provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e90754",
   "metadata": {},
   "source": [
    "The code below will provide you with a dataframe (like an excel file with the artist information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a1412f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"Cezanne\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95f31571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_provenance(url, df=pd.DataFrame()):\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    info = data['info']\n",
    "    records = data['records']\n",
    "    \n",
    "    # Extract relevant data from each record\n",
    "    record_data = []\n",
    "    for record in records:\n",
    "        record_data.append({\n",
    "            'title': record['title'],\n",
    "            'classification': record['classification'],\n",
    "            'century': record['century'],\n",
    "            'provenance': record['provenance']\n",
    "        })\n",
    "    \n",
    "    # Append record data to DataFrame\n",
    "    df = pd.concat([df, pd.DataFrame(record_data)], ignore_index=True)\n",
    "    \n",
    "    # Recursively call pagination function for next page, if it exists\n",
    "    if 'next' in info:\n",
    "        return results_provenance(info['next'], df)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a3d4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://api.harvardartmuseums.org/object?person={artist}&apikey={key}'\n",
    "df = results_provenance(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7bb4d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3495c",
   "metadata": {},
   "source": [
    "## Results with no Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a349824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(url, df=pd.DataFrame()):\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    info = data['info']\n",
    "    records = data['records']\n",
    "    \n",
    "    # Extract relevant data from each record\n",
    "    record_data = []\n",
    "    for record in records:\n",
    "        record_data.append({\n",
    "            'title': record['title'],\n",
    "            'classification': record['classification'],\n",
    "            'century': record['century']\n",
    "        })\n",
    "    \n",
    "    # Append record data to DataFrame\n",
    "    df = pd.concat([df, pd.DataFrame(record_data)], ignore_index=True)\n",
    "    \n",
    "    # Recursively call pagination function for next page, if it exists\n",
    "    if 'next' in info:\n",
    "        return results(info['next'], df)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "483fc214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>classification</th>\n",
       "      <th>century</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocky Landscape, after Cézanne</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>20th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tree Trunks</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forest Interior</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>House Among Trees</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Portrait of a Man (Emile Zola?); verso: Study ...</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Study of Trees</td>\n",
       "      <td>Paintings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Still Life with Game Birds</td>\n",
       "      <td>Paintings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jules Peyron</td>\n",
       "      <td>Paintings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Plaster Cupid</td>\n",
       "      <td>Paintings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Small Houses in Pontoise</td>\n",
       "      <td>Paintings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Small Bathers</td>\n",
       "      <td>Prints</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Female Figure Ornamenting a Clock; verso: Frag...</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Study of an Ecorché and a Man's Face in Profil...</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sheet of Studies, including a Skull</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Small Bathers</td>\n",
       "      <td>Prints</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Artist</td>\n",
       "      <td>Prints</td>\n",
       "      <td>19th-20th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Armand Guillaumin, Hanged</td>\n",
       "      <td>Prints</td>\n",
       "      <td>19th-20th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Large Bathers</td>\n",
       "      <td>Prints</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mont Sainte-Victoire (recto and verso)</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Head of a Young Boy</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th-20th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Portrait of Ambroise Vollard</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Heads of Mme Cézanne and Louis-Auguste Cézanne...</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>View of Mont Sainte Victoire; verso: Study of ...</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Study of a Nude Figure</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Old Fisherman</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th-20th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sketch of Trees; verso: Undergrowth</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Still Life with Commode</td>\n",
       "      <td>Paintings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Large Pine, Study</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>X-radiograph(s) of \"Nature Morte a la Commode\"</td>\n",
       "      <td>Photographs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>X-radiograph(s) of \"Still Life With Commode\"</td>\n",
       "      <td>Photographs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>X-radiograph(s) of \"Jules Peyron\"</td>\n",
       "      <td>Photographs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Plaster Cupid</td>\n",
       "      <td>Drawings</td>\n",
       "      <td>19th century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title classification  \\\n",
       "0                      Rocky Landscape, after Cézanne       Drawings   \n",
       "1                                         Tree Trunks       Drawings   \n",
       "2                                     Forest Interior       Drawings   \n",
       "3                                   House Among Trees       Drawings   \n",
       "4   Portrait of a Man (Emile Zola?); verso: Study ...       Drawings   \n",
       "5                                      Study of Trees      Paintings   \n",
       "6                          Still Life with Game Birds      Paintings   \n",
       "7                                        Jules Peyron      Paintings   \n",
       "8                                       Plaster Cupid      Paintings   \n",
       "9                            Small Houses in Pontoise      Paintings   \n",
       "10                                  The Small Bathers         Prints   \n",
       "11  Female Figure Ornamenting a Clock; verso: Frag...       Drawings   \n",
       "12  Study of an Ecorché and a Man's Face in Profil...       Drawings   \n",
       "13                Sheet of Studies, including a Skull       Drawings   \n",
       "14                                  The Small Bathers         Prints   \n",
       "15                                         The Artist         Prints   \n",
       "16                          Armand Guillaumin, Hanged         Prints   \n",
       "17                                  The Large Bathers         Prints   \n",
       "18             Mont Sainte-Victoire (recto and verso)       Drawings   \n",
       "19                                Head of a Young Boy       Drawings   \n",
       "20                       Portrait of Ambroise Vollard       Drawings   \n",
       "21  Heads of Mme Cézanne and Louis-Auguste Cézanne...       Drawings   \n",
       "22  View of Mont Sainte Victoire; verso: Study of ...       Drawings   \n",
       "23                             Study of a Nude Figure       Drawings   \n",
       "24                                      Old Fisherman       Drawings   \n",
       "25                Sketch of Trees; verso: Undergrowth       Drawings   \n",
       "26                            Still Life with Commode      Paintings   \n",
       "27                                  Large Pine, Study       Drawings   \n",
       "28     X-radiograph(s) of \"Nature Morte a la Commode\"    Photographs   \n",
       "29       X-radiograph(s) of \"Still Life With Commode\"    Photographs   \n",
       "30                  X-radiograph(s) of \"Jules Peyron\"    Photographs   \n",
       "31                                      Plaster Cupid       Drawings   \n",
       "\n",
       "              century  \n",
       "0        20th century  \n",
       "1        19th century  \n",
       "2        19th century  \n",
       "3        19th century  \n",
       "4        19th century  \n",
       "5        19th century  \n",
       "6        19th century  \n",
       "7        19th century  \n",
       "8        19th century  \n",
       "9        19th century  \n",
       "10       19th century  \n",
       "11       19th century  \n",
       "12       19th century  \n",
       "13       19th century  \n",
       "14       19th century  \n",
       "15  19th-20th century  \n",
       "16  19th-20th century  \n",
       "17       19th century  \n",
       "18       19th century  \n",
       "19  19th-20th century  \n",
       "20       19th century  \n",
       "21       19th century  \n",
       "22       19th century  \n",
       "23       19th century  \n",
       "24  19th-20th century  \n",
       "25       19th century  \n",
       "26       19th century  \n",
       "27       19th century  \n",
       "28               None  \n",
       "29               None  \n",
       "30               None  \n",
       "31       19th century  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://api.harvardartmuseums.org/object?person={artist}&apikey={key}'\n",
    "results(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d2d46",
   "metadata": {},
   "source": [
    "## Download Images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be161c6",
   "metadata": {},
   "source": [
    "The function below will download all images for a particular artist, now it could also be that is not only the artist, so we have to do some API research, but that is your job, you need to know what you want to show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b603c",
   "metadata": {},
   "source": [
    "You simply have to modify the artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d268b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"Cezanne\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eefc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_artist_paintings(artist,key):\n",
    "    # Set up API endpoint and parameters\n",
    "    endpoint = \"https://api.harvardartmuseums.org/object\"\n",
    "    params = {\n",
    "        \"apikey\": key,\n",
    "        \"person\": artist,\n",
    "        \"classification\": \"Paintings\",\n",
    "    }\n",
    "\n",
    "    # Send API request and extract relevant data from JSON response\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()[\"records\"]\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        data = []\n",
    "\n",
    "    # Create directory for images if it doesn't exist\n",
    "    directory_name = artist.lower().replace(' ', '_') + '_paintings'\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "\n",
    "    # Download and save images\n",
    "    for record in data:\n",
    "        object_number = record[\"objectnumber\"]\n",
    "        image_url = record[\"primaryimageurl\"]\n",
    "        if image_url:\n",
    "            response = requests.get(image_url)\n",
    "            if response.status_code == 200:\n",
    "                image_data = response.content\n",
    "                with open(f\"{directory_name}/{object_number}.jpg\", \"wb\") as f:\n",
    "                    f.write(image_data)\n",
    "                    print(f\"Saved image for {object_number}\")\n",
    "            else:\n",
    "                print(f\"Error downloading image for {object_number}\")\n",
    "        else:\n",
    "            print(f\"No image found for {object_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d429057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image for 1998.305\n",
      "Saved image for 1976.70\n",
      "Saved image for 1961.144\n",
      "Saved image for 1964.72\n",
      "Saved image for 1934.28\n",
      "Saved image for 1951.46\n"
     ]
    }
   ],
   "source": [
    "download_artist_paintings(artist,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223f3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models Prompts and Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7e6dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /home/codespace/.local/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Collecting tqdm (from openai)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting aiohttp (from openai)\n",
      "  Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
      "  Using cached yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: tqdm, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.4.0 multidict-6.0.4 openai-0.27.8 tqdm-4.65.0 yarl-1.9.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting dotenv\n",
      "  Using cached dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[76 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /home/codespace/.local/lib/python3.10/site-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m   error: subprocess-exited-with-error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   × python setup.py egg_info did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   │ exit code: 1\n",
      "  \u001b[31m   \u001b[0m   ╰─> [16 lines of output]\n",
      "  \u001b[31m   \u001b[0m       Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m         File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m         File \"<pip-setuptools-caller>\", line 14, in <module>\n",
      "  \u001b[31m   \u001b[0m         File \"/tmp/pip-wheel-6ax8yv3i/distribute_7f646686af1643e29a98edf1ef2eb208/setuptools/__init__.py\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m           from setuptools.extension import Extension, Library\n",
      "  \u001b[31m   \u001b[0m         File \"/tmp/pip-wheel-6ax8yv3i/distribute_7f646686af1643e29a98edf1ef2eb208/setuptools/extension.py\", line 5, in <module>\n",
      "  \u001b[31m   \u001b[0m           from setuptools.dist import _get_unpatched\n",
      "  \u001b[31m   \u001b[0m         File \"/tmp/pip-wheel-6ax8yv3i/distribute_7f646686af1643e29a98edf1ef2eb208/setuptools/dist.py\", line 7, in <module>\n",
      "  \u001b[31m   \u001b[0m           from setuptools.command.install import install\n",
      "  \u001b[31m   \u001b[0m         File \"/tmp/pip-wheel-6ax8yv3i/distribute_7f646686af1643e29a98edf1ef2eb208/setuptools/command/__init__.py\", line 8, in <module>\n",
      "  \u001b[31m   \u001b[0m           from setuptools.command import install_scripts\n",
      "  \u001b[31m   \u001b[0m         File \"/tmp/pip-wheel-6ax8yv3i/distribute_7f646686af1643e29a98edf1ef2eb208/setuptools/command/install_scripts.py\", line 3, in <module>\n",
      "  \u001b[31m   \u001b[0m           from pkg_resources import Distribution, PathMetadata, ensure_directory\n",
      "  \u001b[31m   \u001b[0m         File \"/tmp/pip-wheel-6ax8yv3i/distribute_7f646686af1643e29a98edf1ef2eb208/pkg_resources.py\", line 1518, in <module>\n",
      "  \u001b[31m   \u001b[0m           register_loader_type(importlib_bootstrap.SourceFileLoader, DefaultProvider)\n",
      "  \u001b[31m   \u001b[0m       AttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'\n",
      "  \u001b[31m   \u001b[0m       [end of output]\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m error: metadata-generation-failed\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m × Encountered error while generating package metadata.\n",
      "  \u001b[31m   \u001b[0m ╰─> See above for output.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m note: This is an issue with the package mentioned above, not pip.\n",
      "  \u001b[31m   \u001b[0m hint: See above for details.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/setuptools/installer.py\", line 96, in _fetch_build_egg_no_warn\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/usr/local/python/3.10.8/lib/python3.10/subprocess.py\", line 369, in check_call\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['/usr/local/python/3.10.8/bin/python', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmpmmkoe51i', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-uamidtew/dotenv_09d0f729427a46f5a8f4bcf8db5d30a4/setup.py\", line 13, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='dotenv',\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/setuptools/__init__.py\", line 106, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/setuptools/__init__.py\", line 79, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     _fetch_build_eggs(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/setuptools/__init__.py\", line 84, in _fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/setuptools/dist.py\", line 917, in fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     return _fetch_build_eggs(self, requires)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/setuptools/installer.py\", line 38, in _fetch_build_eggs\n",
      "  \u001b[31m   \u001b[0m     resolved_dists = pkg_resources.working_set.resolve(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 827, in resolve\n",
      "  \u001b[31m   \u001b[0m     dist = self._resolve_dist(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 863, in _resolve_dist\n",
      "  \u001b[31m   \u001b[0m     dist = best[req.key] = env.best_match(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 1133, in best_match\n",
      "  \u001b[31m   \u001b[0m     return self.obtain(req, installer)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/pkg_resources/__init__.py\", line 1145, in obtain\n",
      "  \u001b[31m   \u001b[0m     return installer(requirement)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/codespace/.local/lib/python3.10/site-packages/setuptools/installer.py\", line 98, in _fetch_build_egg_no_warn\n",
      "  \u001b[31m   \u001b[0m     raise DistutilsError(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m distutils.errors.DistutilsError: Command '['/usr/local/python/3.10.8/bin/python', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/tmp/tmpmmkoe51i', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "ERROR: unknown command \"intstall\" - maybe you meant \"install\"\n",
      "Collecting chroma\n",
      "  Downloading Chroma-0.2.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: chroma\n",
      "  Building wheel for chroma (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chroma: filename=Chroma-0.2.0-py3-none-any.whl size=7096 sha256=be154d373e2df7e4d5081a647b19b0633dba18ae97255e433e926d006e601001\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/58/74/75/a6ab7999ae473ecbe819bc5cae9ccb902429dd6c60795f5112\n",
      "Successfully built chroma\n",
      "Installing collected packages: chroma\n",
      "Successfully installed chroma-0.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.6.3 tiktoken-0.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install os\n",
    "!pip install dotenv\n",
    "!pip install langchain\n",
    "!pip install chroma\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c35c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d1d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\":\"user\", \"content\":prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages=messages,\n",
    "        temperature = 0,\n",
    "        \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a449543e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666a6b3a",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10a7f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.0.253-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
      "  Using cached langsmith-0.0.19-py3-none-any.whl (31 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain)\n",
      "  Using cached numexpr-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.24.3)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Collecting pydantic<2,>=1 (from langchain)\n",
      "  Using cached pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/codespace/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: pydantic, numexpr, mypy-extensions, marshmallow, greenlet, typing-inspect, SQLAlchemy, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
      "Successfully installed SQLAlchemy-2.0.19 dataclasses-json-0.5.14 greenlet-2.0.2 langchain-0.0.253 langsmith-0.0.19 marshmallow-3.20.1 mypy-extensions-1.0.0 numexpr-2.8.4 openapi-schema-pydantic-1.2.4 pydantic-1.10.12 typing-inspect-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91448de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddcc79a",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57679a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4cd82a",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41966b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d95f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "189b4785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41fb81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5656bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc14301d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], output_parser=None, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d597e8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a5a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb95cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58adf4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "743a6f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain.schema.messages.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89adda1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7db793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb2069d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie! And to make things even worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, my friend!\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7af204",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8e11142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-3.14.0-py3-none-any.whl (269 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-3.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57d7d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"documents/forged1.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cf9e125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98b31f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18f6d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting Fraud And Forgery In Papers And Documents\n",
      "The art of detecting forgery or fraud, in checks, drafts, documents,\n",
      "seals, writing materials, or in the characters themselves is a study\n",
      "that has attracted handwriting experts since its study was taken up.\n",
      "There are almost infallible rules for the work and in this chapter is\n",
      "given several new methods of research that will prove of the utmost\n",
      "value to the public.\n",
      "It is not an uncommon occurrence that wills and other public documents\n",
      "are changed by the insertion of extra or substituted pages, thereby\n",
      "changing the character of the instrument. Where this is suspected\n",
      "careful inspection of the paper should be made--first, as to its shade\n",
      "of color and fiber, under a microscope; second, as to its ruling;\n",
      "third, as to its water-mark; fourth, as to any indications that the\n",
      "sheets have been separated since their original attachment; fifth, as\n",
      "to the writing--whether or not it bears the harmonious character of\n",
      "the continuous writing, with the s\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc09a7c",
   "metadata": {},
   "source": [
    "## Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e70f812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42d10224",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad383700",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab5dc2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2e51cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccbbf57",
   "metadata": {},
   "source": [
    "## Token Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df916ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03bd6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2c11b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "666766b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Detecting Fraud And Forgery In Papers And Documents', metadata={'source': 'documents/forged1.pdf', 'page': 0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb71487a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'documents/forged1.pdf', 'page': 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "112f9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"documents/forged1.pdf\"),\n",
    "    PyPDFLoader(\"documents/congress.pdf\"),\n",
    "    PyPDFLoader(\"documents/dictionary.pdf\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34f68ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34bfbe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "957c00a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33fde5",
   "metadata": {},
   "source": [
    "## Vectors an Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d627a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.5-py3-none-any.whl (402 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /home/codespace/.local/lib/python3.10/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (1.10.12)\n",
      "Collecting chroma-hnswlib==0.7.2 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.2-cp310-cp310-linux_x86_64.whl\n",
      "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
      "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
      "  Using cached uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/codespace/.local/lib/python3.10/site-packages (from chromadb) (1.24.3)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from chromadb) (4.6.3)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Using cached pulsar_client-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from chromadb) (7.3.1)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.0.0-py3-none-any.whl (31 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /home/codespace/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.28->chromadb) (2.0.3)\n",
      "Collecting click>=7.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached click-8.1.6-py3-none-any.whl (97 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.1)\n",
      "Installing collected packages: tokenizers, pypika, monotonic, flatbuffers, websockets, uvloop, python-dotenv, pulsar-client, protobuf, importlib-resources, humanfriendly, httptools, h11, click, chroma-hnswlib, backoff, watchfiles, uvicorn, starlette, posthog, coloredlogs, onnxruntime, fastapi, chromadb\n",
      "Successfully installed backoff-2.2.1 chroma-hnswlib-0.7.2 chromadb-0.4.5 click-8.1.6 coloredlogs-15.0.1 fastapi-0.99.1 flatbuffers-23.5.26 h11-0.14.0 httptools-0.6.0 humanfriendly-10.0 importlib-resources-6.0.0 monotonic-1.6 onnxruntime-1.15.1 posthog-3.0.1 protobuf-4.23.4 pulsar-client-3.2.0 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 tokenizers-0.13.3 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2396ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "526e29bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b78a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8b59912",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[91mYour system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vectordb \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(\n\u001b[1;32m      2\u001b[0m     documents\u001b[39m=\u001b[39;49msplits,\n\u001b[1;32m      3\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m      4\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/python/3.10.8/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:603\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    602\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 603\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m    604\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    605\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    606\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    607\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    608\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    609\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    610\u001b[0m     client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    611\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    612\u001b[0m     collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    613\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    614\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/python/3.10.8/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:558\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    527\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    538\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    539\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \n\u001b[1;32m    541\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m     chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    559\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    560\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    561\u001b[0m         persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    562\u001b[0m         client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    563\u001b[0m         client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    564\u001b[0m         collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    565\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m     chroma_collection\u001b[39m.\u001b[39madd_texts(texts\u001b[39m=\u001b[39mtexts, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n\u001b[1;32m    568\u001b[0m     \u001b[39mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m/usr/local/python/3.10.8/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:81\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initialize with Chroma client.\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/python/3.10.8/lib/python3.10/site-packages/chromadb/__init__.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m         sys\u001b[39m.\u001b[39mmodules[\u001b[39m\"\u001b[39m\u001b[39msqlite3\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mpysqlite3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\\033\u001b[39;00m\u001b[39m[91mYour system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\u001b[39m\u001b[39m\\033\u001b[39;00m\u001b[39m[0m\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\\033\u001b[39;00m\u001b[39m[94mPlease visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.\u001b[39m\u001b[39m\\033\u001b[39;00m\u001b[39m[0m\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfigure\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Override Chroma's default settings, environment variables or .env files\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[91mYour system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.\u001b[0m"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
