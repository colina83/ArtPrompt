{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 3668/3668 [00:00<00:00, 10408.58 examples/s]\n",
      "c:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\datasets\\arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "tf_validation_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[30522,768] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Mul] name: \n\nCall arguments received by layer 'bert' (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • attention_mask=tf.Tensor(shape=(1, 2), dtype=int32)\n  • token_type_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m TFAutoModelForSequenceClassification\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m TFAutoModelForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(checkpoint, num_labels\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:516\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    515\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 516\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    517\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    518\u001b[0m     )\n\u001b[0;32m    519\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    520\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    521\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:2908\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2906\u001b[0m         model\u001b[39m.\u001b[39mbuild()  \u001b[39m# build the network with dummy inputs\u001b[39;00m\n\u001b[0;32m   2907\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2908\u001b[0m     model\u001b[39m.\u001b[39;49mbuild()  \u001b[39m# build the network with dummy inputs\u001b[39;00m\n\u001b[0;32m   2910\u001b[0m \u001b[39mif\u001b[39;00m safetensors_from_pt:\n\u001b[0;32m   2911\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodeling_tf_pytorch_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_pytorch_state_dict_in_tf2_model\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1138\u001b[0m, in \u001b[0;36mTFPreTrainedModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39m# Set the serving spec quickly to ensure that Keras doesn't use the specific dummy input shapes as the spec\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[39m# Setting it in build() allows users to override the shape when loading a non-pretrained model from config\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_save_spec(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature)\n\u001b[1;32m-> 1138\u001b[0m \u001b[39mself\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdummy_inputs, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:1569\u001b[0m, in \u001b[0;36mTFBertForSequenceClassification.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[0;32m   1540\u001b[0m \u001b[39m@unpack_inputs\u001b[39m\n\u001b[0;32m   1541\u001b[0m \u001b[39m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbatch_size, sequence_length\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1542\u001b[0m \u001b[39m@add_code_sample_docstrings\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     training: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1562\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[TFSequenceClassifierOutput, Tuple[tf\u001b[39m.\u001b[39mTensor]]:\n\u001b[0;32m   1563\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m \u001b[39m    labels (`tf.Tensor` or `np.ndarray` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1565\u001b[0m \u001b[39m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m \u001b[39m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1567\u001b[0m \u001b[39m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1568\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1569\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1570\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1571\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1572\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1573\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1574\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1575\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1576\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1577\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1578\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1579\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m   1580\u001b[0m     )\n\u001b[0;32m   1581\u001b[0m     pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1582\u001b[0m     pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(inputs\u001b[39m=\u001b[39mpooled_output, training\u001b[39m=\u001b[39mtraining)\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:426\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    425\u001b[0m unpacked_inputs \u001b[39m=\u001b[39m input_processing(func, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munpacked_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:780\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mif\u001b[39;00m token_type_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m     token_type_ids \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfill(dims\u001b[39m=\u001b[39minput_shape, value\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 780\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m    781\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    782\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    783\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m    784\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    785\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m    786\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[0;32m    787\u001b[0m )\n\u001b[0;32m    789\u001b[0m \u001b[39m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[39m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[0;32m    791\u001b[0m \u001b[39m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[39m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[39m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m attention_mask_shape \u001b[39m=\u001b[39m shape_list(attention_mask)\n",
      "File \u001b[1;32mc:\\Users\\Francisco.Colina\\Documents\\Code\\ArtPrompt\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:161\u001b[0m, in \u001b[0;36mTFBertEmbeddings.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, input_shape: tf\u001b[39m.\u001b[39mTensorShape):\n\u001b[0;32m    160\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mword_embeddings\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 161\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    162\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    163\u001b[0m             shape\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mvocab_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size],\n\u001b[0;32m    164\u001b[0m             initializer\u001b[39m=\u001b[39mget_initializer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitializer_range),\n\u001b[0;32m    165\u001b[0m         )\n\u001b[0;32m    167\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mtoken_type_embeddings\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    169\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    170\u001b[0m             shape\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mtype_vocab_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size],\n\u001b[0;32m    171\u001b[0m             initializer\u001b[39m=\u001b[39mget_initializer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitializer_range),\n\u001b[0;32m    172\u001b[0m         )\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'bert' (type TFBertMainLayer).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[30522,768] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Mul] name: \n\nCall arguments received by layer 'bert' (type TFBertMainLayer):\n  • input_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • attention_mask=tf.Tensor(shape=(1, 2), dtype=int32)\n  • token_type_ids=tf.Tensor(shape=(1, 2), dtype=int32)\n  • position_ids=None\n  • head_mask=None\n  • inputs_embeds=None\n  • encoder_hidden_states=None\n  • encoder_attention_mask=None\n  • past_key_values=None\n  • use_cache=None\n  • output_attentions=False\n  • output_hidden_states=False\n  • return_dict=True\n  • training=False"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlosses\u001b[39;00m \u001b[39mimport\u001b[39;00m SparseCategoricalCrossentropy\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      4\u001b[0m     optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     loss\u001b[39m=\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      6\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m      9\u001b[0m     tf_train_dataset,\n\u001b[0;32m     10\u001b[0m     validation_data\u001b[39m=\u001b[39mtf_validation_dataset,)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_validation_dataset,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
